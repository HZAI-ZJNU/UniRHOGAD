# ======================================================================
#   Base Configuration for Multi-Graph Datasets
# ======================================================================

# e.g. bm/dgl/bm_mn_dgl, bm/dgl/bm_ms_dgl, bm/dgl/bm_mn_mt_dgl, mnist_processed/mnist0_strict, mnist_processed/mnist1_strict, TGroup, mutag/dgl/mutag
dataset: 'mutag/dgl/mutag'

# --- 路径与设备 ---
data_dir: ./data
results_dir: ./results
save_dir: ./pretrained
checkpoint_dir: './checkpoints'
device: cuda

# --- 训练控制 ---
seed: 42
num_trials: 5
epochs: 200
patience: 30
batch_size: 16
composite_score_weights:
  AUPRC: 2.0   # 对于 Reddit，我们将 AUPRC 的权重设为 0
  AUROC: 0.5   # 将 AUROC 的权重设为 1.0，使其成为主导指标
  MacroF1: 0.0 # MacroF1 仍然不参与

# --- 模型与优化器 ---
lr: 5e-4
l2: 1e-5
hid_dim: 128
dropout: 0.3
activation: 'ReLU'
residual: True
norm: 'layernorm'
base_gnn_layers: 2
final_mlp_layers: 2
gna_proj_dim: 128

# --- 预训练模型架构 ---
pretrain_path: './pretrained/mutag_dgl_mutag_enc_gcn2_dec_gcn1_e100_h128_loss_mse.pt'
pretrain_encoder_type: 'gcn'
pretrain_decoder_type: 'gcn'
pretrain_hid_dim: 128
pretrain_encoder_num_layer: 2
pretrain_decoder_num_layer: 1

# --- 预训练 PAA 参数 ---
pretrain_epochs: 100
pretrain_lr: 5e-3
pretrain_batch_size: 512
scheduler_step: 50
scheduler_gamma: 0.5
mask_ratio: 0.5       # GraphMAE 重建损失的掩码率
replace_ratio: 0.1    # GraphMAE 重建损失的替换率
drop_edge_rate: 0.2   # GraphMAE 重建损失的边丢弃率
loss_fn: 'sce'
alpha_l: 2.0
w_contrastive: 0.3    # 预训练中对比损失的权重
w_recon: 1.0          # 预训练中重建损失的权重

# --- Uni-RHO-GAD 特定参数 ---
all_tasks: 'ng' # 多图任务
cross_modes: "ng2ng,n2ng,g2ng"
w_one_class: 2.0
w_gna: 5.0
w_classification: 1.0

# --- 数据增强控制 ---
# 核心开关: 控制是否在微调阶段对多图进行在线增强
use_downstream_multi_graph_aug: true # <--- 建议设为 True 来启用

# 新增: 多图在线增强的具体参数 (仅在 use_downstream_multi_graph_aug 为 True 时生效)
aug_drop_node_rate: 0.2
aug_perturb_edge_rate: 0.2
aug_mask_feature_rate: 0.2
